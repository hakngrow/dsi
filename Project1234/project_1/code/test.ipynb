{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: SAT & ACT Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first markdown cell in a notebook is a great place to provide an overview of your entire project. You will likely want to at least state your\n",
    "\n",
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the problem you are finding answers for from the data given.\n",
    "\n",
    "Business Context\n",
    "Business Objective\n",
    "Data Objective\n",
    "Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executive Summary\n",
    "\n",
    "If you want to, it's great to use relative links to direct your audience to various sections of a notebook. **HERE'S A DEMONSTRATION WITH THE CURRENT SECTION HEADERS**:\n",
    "\n",
    "### Contents:\n",
    "- [2017 Data Import & Cleaning](#Data-Import-and-Cleaning)\n",
    "- [2018 Data Import and Cleaning](#2018-Data-Import-and-Cleaning)\n",
    "- [Exploratory Data Analysis](#Exploratory-Data-Analysis)\n",
    "- [Data Visualization](#Visualize-the-data)\n",
    "- [Descriptive and Inferential Statistics](#Descriptive-and-Inferential-Statistics)\n",
    "- [Outside Research](#Outside-Research)\n",
    "- [Conclusions and Recommendations](#Conclusions-and-Recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you combine your problem statement, executive summary, data dictionary, and conclusions/recommendations, you have an amazing README.md file that quickly aligns your audience to the contents of your project.** Don't forget to cite your data sources!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*All libraries used should be added here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2017 Data Import and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Read In SAT & ACT  Data\n",
    "\n",
    "Read in the `sat_2017.csv` and `act_2017.csv` files and assign them to appropriately named pandas dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sat_2017 = pd.read_csv('../data/sat_2017.csv')\n",
    "df_act_2017 = pd.read_csv('../data/act_2017.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Display Data\n",
    "\n",
    "Print the first 10 rows of each dataframe to your jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>Evidence-Based Reading and Writing</th>\n",
       "      <th>Math</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>5%</td>\n",
       "      <td>593</td>\n",
       "      <td>572</td>\n",
       "      <td>1165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>38%</td>\n",
       "      <td>547</td>\n",
       "      <td>533</td>\n",
       "      <td>1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>30%</td>\n",
       "      <td>563</td>\n",
       "      <td>553</td>\n",
       "      <td>1116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>3%</td>\n",
       "      <td>614</td>\n",
       "      <td>594</td>\n",
       "      <td>1208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>53%</td>\n",
       "      <td>531</td>\n",
       "      <td>524</td>\n",
       "      <td>1055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>11%</td>\n",
       "      <td>606</td>\n",
       "      <td>595</td>\n",
       "      <td>1201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>100%</td>\n",
       "      <td>530</td>\n",
       "      <td>512</td>\n",
       "      <td>1041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>100%</td>\n",
       "      <td>503</td>\n",
       "      <td>492</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>100%</td>\n",
       "      <td>482</td>\n",
       "      <td>468</td>\n",
       "      <td>950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Florida</td>\n",
       "      <td>83%</td>\n",
       "      <td>520</td>\n",
       "      <td>497</td>\n",
       "      <td>1017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  State Participation  Evidence-Based Reading and Writing  \\\n",
       "0               Alabama            5%                                 593   \n",
       "1                Alaska           38%                                 547   \n",
       "2               Arizona           30%                                 563   \n",
       "3              Arkansas            3%                                 614   \n",
       "4            California           53%                                 531   \n",
       "5              Colorado           11%                                 606   \n",
       "6           Connecticut          100%                                 530   \n",
       "7              Delaware          100%                                 503   \n",
       "8  District of Columbia          100%                                 482   \n",
       "9               Florida           83%                                 520   \n",
       "\n",
       "   Math  Total  \n",
       "0   572   1165  \n",
       "1   533   1080  \n",
       "2   553   1116  \n",
       "3   594   1208  \n",
       "4   524   1055  \n",
       "5   595   1201  \n",
       "6   512   1041  \n",
       "7   492    996  \n",
       "8   468    950  \n",
       "9   497   1017  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sat_2017.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Evidence-Based Reading and Writing</th>\n",
       "      <th>Math</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>51.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>569.117647</td>\n",
       "      <td>547.627451</td>\n",
       "      <td>1126.098039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>45.666901</td>\n",
       "      <td>84.909119</td>\n",
       "      <td>92.494812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>482.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>950.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>533.500000</td>\n",
       "      <td>522.000000</td>\n",
       "      <td>1055.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>559.000000</td>\n",
       "      <td>548.000000</td>\n",
       "      <td>1107.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>613.000000</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>1212.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>644.000000</td>\n",
       "      <td>651.000000</td>\n",
       "      <td>1295.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Evidence-Based Reading and Writing        Math        Total\n",
       "count                           51.000000   51.000000    51.000000\n",
       "mean                           569.117647  547.627451  1126.098039\n",
       "std                             45.666901   84.909119    92.494812\n",
       "min                            482.000000   52.000000   950.000000\n",
       "25%                            533.500000  522.000000  1055.500000\n",
       "50%                            559.000000  548.000000  1107.000000\n",
       "75%                            613.000000  599.000000  1212.000000\n",
       "max                            644.000000  651.000000  1295.000000"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sat_2017.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Participation</th>\n",
       "      <th>English</th>\n",
       "      <th>Math</th>\n",
       "      <th>Reading</th>\n",
       "      <th>Science</th>\n",
       "      <th>Composite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>National</td>\n",
       "      <td>60%</td>\n",
       "      <td>20.3</td>\n",
       "      <td>20.7</td>\n",
       "      <td>21.4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>100%</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.4</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>65%</td>\n",
       "      <td>18.7</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.4</td>\n",
       "      <td>19.9</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>62%</td>\n",
       "      <td>18.6</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.1</td>\n",
       "      <td>19.8</td>\n",
       "      <td>19.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>100%</td>\n",
       "      <td>18.9</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>California</td>\n",
       "      <td>31%</td>\n",
       "      <td>22.5</td>\n",
       "      <td>22.7</td>\n",
       "      <td>23.1</td>\n",
       "      <td>22.2</td>\n",
       "      <td>22.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>100%</td>\n",
       "      <td>20.1</td>\n",
       "      <td>20.3</td>\n",
       "      <td>21.2</td>\n",
       "      <td>20.9</td>\n",
       "      <td>20.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Connecticut</td>\n",
       "      <td>31%</td>\n",
       "      <td>25.5</td>\n",
       "      <td>24.6</td>\n",
       "      <td>25.6</td>\n",
       "      <td>24.6</td>\n",
       "      <td>25.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>18%</td>\n",
       "      <td>24.1</td>\n",
       "      <td>23.4</td>\n",
       "      <td>24.8</td>\n",
       "      <td>23.6</td>\n",
       "      <td>24.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>32%</td>\n",
       "      <td>24.4</td>\n",
       "      <td>23.5</td>\n",
       "      <td>24.9</td>\n",
       "      <td>23.5</td>\n",
       "      <td>24.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  State Participation  English  Math  Reading  Science  \\\n",
       "0              National           60%     20.3  20.7     21.4     21.0   \n",
       "1               Alabama          100%     18.9  18.4     19.7     19.4   \n",
       "2                Alaska           65%     18.7  19.8     20.4     19.9   \n",
       "3               Arizona           62%     18.6  19.8     20.1     19.8   \n",
       "4              Arkansas          100%     18.9  19.0     19.7     19.5   \n",
       "5            California           31%     22.5  22.7     23.1     22.2   \n",
       "6              Colorado          100%     20.1  20.3     21.2     20.9   \n",
       "7           Connecticut           31%     25.5  24.6     25.6     24.6   \n",
       "8              Delaware           18%     24.1  23.4     24.8     23.6   \n",
       "9  District of Columbia           32%     24.4  23.5     24.9     23.5   \n",
       "\n",
       "  Composite  \n",
       "0      21.0  \n",
       "1      19.2  \n",
       "2      19.8  \n",
       "3      19.7  \n",
       "4      19.4  \n",
       "5      22.8  \n",
       "6      20.8  \n",
       "7      25.2  \n",
       "8      24.1  \n",
       "9      24.2  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_act_2017.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English</th>\n",
       "      <th>Math</th>\n",
       "      <th>Reading</th>\n",
       "      <th>Science</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>20.919231</td>\n",
       "      <td>21.173077</td>\n",
       "      <td>22.001923</td>\n",
       "      <td>21.040385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.332132</td>\n",
       "      <td>1.963602</td>\n",
       "      <td>2.048672</td>\n",
       "      <td>3.151113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>16.300000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>2.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.400000</td>\n",
       "      <td>20.475000</td>\n",
       "      <td>19.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>20.550000</td>\n",
       "      <td>20.900000</td>\n",
       "      <td>21.700000</td>\n",
       "      <td>21.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>23.300000</td>\n",
       "      <td>23.100000</td>\n",
       "      <td>24.125000</td>\n",
       "      <td>22.525000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>25.500000</td>\n",
       "      <td>25.300000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>24.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         English       Math    Reading    Science\n",
       "count  52.000000  52.000000  52.000000  52.000000\n",
       "mean   20.919231  21.173077  22.001923  21.040385\n",
       "std     2.332132   1.963602   2.048672   3.151113\n",
       "min    16.300000  18.000000  18.100000   2.300000\n",
       "25%    19.000000  19.400000  20.475000  19.900000\n",
       "50%    20.550000  20.900000  21.700000  21.150000\n",
       "75%    23.300000  23.100000  24.125000  22.525000\n",
       "max    25.500000  25.300000  26.000000  24.900000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_act_2017.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Verbally Describe Data\n",
    "\n",
    "Take your time looking through the data and thoroughly describe the data in the markdown cell below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No null/missing values from both datasets.\n",
    "\n",
    "Participation rates need to be converted to float data type for both datasets.\n",
    "\n",
    "For the SAT dataset, the minimum value for the Math column is 52, while the mean is 547. This seems to indicate an outlier,  further investigation is required.\n",
    "\n",
    "For the ACT dataset, the Composite column needs to be converted to a float data type.\n",
    "\n",
    "For the ACT dataset, the minimum value for the Science column is 2.3, while the mean is 21. This seems to indicate an outlier, further investigation is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51 entries, 0 to 50\n",
      "Data columns (total 5 columns):\n",
      "State                                 51 non-null object\n",
      "Participation                         51 non-null object\n",
      "Evidence-Based Reading and Writing    51 non-null int64\n",
      "Math                                  51 non-null int64\n",
      "Total                                 51 non-null int64\n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 1.6+ KB\n"
     ]
    }
   ],
   "source": [
    "#### 4a. Does the data look complete? \n",
    "df_sat_2017.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52 entries, 0 to 51\n",
      "Data columns (total 7 columns):\n",
      "State            52 non-null object\n",
      "Participation    52 non-null object\n",
      "English          52 non-null float64\n",
      "Math             52 non-null float64\n",
      "Reading          52 non-null float64\n",
      "Science          52 non-null float64\n",
      "Composite        52 non-null object\n",
      "dtypes: float64(4), object(3)\n",
      "memory usage: 2.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_act_2017.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both datasets appear to be complete. However, we need to investigate outliers in both datasets, validating them against their respective source. Also, we need to determine why the Composite score (from ACT dataset), is not loaded as a float data type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4b. Are there any obvious issues with the observations?\n",
    "\n",
    "**What is the minimum *possible* value for each test/subtest? What is the maximum *possible* value?**\n",
    "\n",
    "Consider comparing any questionable values to the sources of your data:\n",
    "- [SAT](https://blog.collegevine.com/here-are-the-average-sat-scores-by-state/)\n",
    "- [ACT](https://blog.prepscholar.com/act-scores-by-state-averages-highs-and-lows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For SAT, both EBRW and Math tests have minimum/maximum possible values of 200/800. For ACT, the 4 subject area and composite scores have a minimum/maximum possible values of 0/36.\n",
    "\n",
    "For the SAT dataset, this indicates that the outlier Math score of 52 is an error as the minimum score is 200.\n",
    "\n",
    "Validating the SAT dataset against its source, shows that the Math score for the state of Maryland should be 524 instead of 52.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate SAT CSV data with data from source @ https://blog.collegevine.com/here-are-the-average-sat-scores-by-state/\n",
    "\n",
    "# Set index (State) and rename columns of SAT CSV and source dataframes to facilitate validation later.\n",
    "\n",
    "sat_2017_columns = ['Participation', 'EBRW', 'Math', 'Total']\n",
    "\n",
    "df_sat_2017.set_index('State', inplace=True)\n",
    "df_sat_2017.columns = sat_2017_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_101e7f46_0054_11ea_8f8d_8c1abfa5692brow0_col2 {\n",
       "            background-color:  yellow;\n",
       "        }</style><table id=\"T_101e7f46_0054_11ea_8f8d_8c1abfa5692b\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Participation</th>        <th class=\"col_heading level0 col1\" >EBRW</th>        <th class=\"col_heading level0 col2\" >Math</th>        <th class=\"col_heading level0 col3\" >Total</th>        <th class=\"col_heading level0 col4\" >Participation_src</th>        <th class=\"col_heading level0 col5\" >EBRW_src</th>        <th class=\"col_heading level0 col6\" >Math_src</th>        <th class=\"col_heading level0 col7\" >Total_src</th>    </tr>    <tr>        <th class=\"index_name level0\" >State</th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_101e7f46_0054_11ea_8f8d_8c1abfa5692blevel0_row0\" class=\"row_heading level0 row0\" >Maryland</th>\n",
       "                        <td id=\"T_101e7f46_0054_11ea_8f8d_8c1abfa5692brow0_col0\" class=\"data row0 col0\" >69%</td>\n",
       "                        <td id=\"T_101e7f46_0054_11ea_8f8d_8c1abfa5692brow0_col1\" class=\"data row0 col1\" >536</td>\n",
       "                        <td id=\"T_101e7f46_0054_11ea_8f8d_8c1abfa5692brow0_col2\" class=\"data row0 col2\" >52</td>\n",
       "                        <td id=\"T_101e7f46_0054_11ea_8f8d_8c1abfa5692brow0_col3\" class=\"data row0 col3\" >1060</td>\n",
       "                        <td id=\"T_101e7f46_0054_11ea_8f8d_8c1abfa5692brow0_col4\" class=\"data row0 col4\" >69%</td>\n",
       "                        <td id=\"T_101e7f46_0054_11ea_8f8d_8c1abfa5692brow0_col5\" class=\"data row0 col5\" >536</td>\n",
       "                        <td id=\"T_101e7f46_0054_11ea_8f8d_8c1abfa5692brow0_col6\" class=\"data row0 col6\" >524</td>\n",
       "                        <td id=\"T_101e7f46_0054_11ea_8f8d_8c1abfa5692brow0_col7\" class=\"data row0 col7\" >1060</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0xd073850>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load source SAT data from tab delimited file into dataframe.\n",
    "df_sat_2017_source = pd.read_csv('../data/sat_2017_source.txt', sep='\\t')\n",
    "df_sat_2017_source.set_index('State', inplace=True)\n",
    "df_sat_2017_source.columns = sat_2017_columns\n",
    "df_sat_2017_source.rename(columns=lambda col_name: col_name + '_src', inplace=True) \n",
    "\n",
    "# Join SAT CSV and source dataframes on row index 'State' \n",
    "df_sat_2017_combined = df_sat_2017.join(df_sat_2017_source, 'State')\n",
    "\n",
    "\n",
    "# Compares the CSV and source columns and returns a list of State index values of rows with mismatched columns\n",
    "def get_mismatched_indexes(df_combined, columns):\n",
    "    \n",
    "    mismatched_indexes = []\n",
    "    \n",
    "    for column in columns:\n",
    "\n",
    "        rows = df_combined[df_combined[column] != df_combined[column + '_src']]\n",
    "        \n",
    "        if len(rows) > 0:\n",
    "            mismatched_indexes.extend(rows.index.values)\n",
    "        \n",
    "    return list(set(mismatched_indexes))\n",
    "\n",
    "\n",
    "df_sat_2017_mismatched = df_sat_2017_combined.loc[get_mismatched_indexes(df_sat_2017_combined, sat_2017_columns)]\n",
    "\n",
    "# Highlight a mismatch between a CSV and source column value\n",
    "def highlight_mismatched(column):\n",
    "    \n",
    "    formats = ['' for i in range(column.size)]\n",
    "    \n",
    "    if column.name in sat_2017_columns:\n",
    "        \n",
    "        is_mismatched = column != df_sat_2017_mismatched[column.name + '_src']\n",
    "\n",
    "        return ['background-color: yellow' if mismatched else '' for mismatched in is_mismatched]\n",
    "    \n",
    "    return formats\n",
    "\n",
    "df_sat_2017_mismatched.style.apply(highlight_mismatched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can validate the ACT CSV dataset against its source, we must ensure that the columns from the CSV dataset and the corresponding column from the source have the same data type.\n",
    "\n",
    "Specifically, the Composite column of the CSV dataset should have been loaded as float values instead of strings. Doing a check on Composite score column, reveals an error in the composite score of the state of Wyoming.\n",
    "\n",
    "We have to fix this error before we can validate the CSV dataset against its source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_12b91026_0054_11ea_9996_8c1abfa5692brow4_col5 {\n",
       "            background-color:  yellow;\n",
       "        }</style><table id=\"T_12b91026_0054_11ea_9996_8c1abfa5692b\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Participation</th>        <th class=\"col_heading level0 col1\" >English</th>        <th class=\"col_heading level0 col2\" >Math</th>        <th class=\"col_heading level0 col3\" >Reading</th>        <th class=\"col_heading level0 col4\" >Science</th>        <th class=\"col_heading level0 col5\" >Composite</th>        <th class=\"col_heading level0 col6\" >is_composite_float</th>    </tr>    <tr>        <th class=\"index_name level0\" >State</th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_12b91026_0054_11ea_9996_8c1abfa5692blevel0_row0\" class=\"row_heading level0 row0\" >Virginia</th>\n",
       "                        <td id=\"T_12b91026_0054_11ea_9996_8c1abfa5692brow0_col0\" class=\"data row0 col0\" >29%</td>\n",
       "                        <td id=\"T_12b91026_0054_11ea_9996_8c1abfa5692brow0_col1\" class=\"data row0 col1\" >23.5</td>\n",
       "                        <td id=\"T_12b91026_0054_11ea_9996_8c1abfa5692brow0_col2\" class=\"data row0 col2\" >23.3</td>\n",
       "                        <td id=\"T_12b91026_0054_11ea_9996_8c1abfa5692brow0_col3\" class=\"data row0 col3\" >24.6</td>\n",
       "                        <td id=\"T_12b91026_0054_11ea_9996_8c1abfa5692brow0_col4\" class=\"data row0 col4\" >23.5</td>\n",
       "                        <td id=\"T_12b91026_0054_11ea_9996_8c1abfa5692brow0_col5\" class=\"data row0 col5\" >23.8</td>\n",
       "                        <td id=\"T_12b91026_0054_11ea_9996_8c1abfa5692brow0_col6\" class=\"data row0 col6\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_12b91026_0054_11ea_9996_8c1abfa5692blevel0_row1\" class=\"row_heading level0 row1\" >Washington</th>\n",
       "                        <td id=\"T_12b91026_0054_11ea_9996_8c1abfa5692brow1_col0\" class=\"data row1 col0\" >29%</td>\n",
       "                        <td id=\"T_12b91026_0054_11ea_9996_8c1abfa5692brow1_col1\" class=\"data row1 col1\" >20.9</td>\n",
       "                        <td id=\"T_12b91026_0054_11ea_9996_8c1abfa5692brow1_col2\" class=\"data row1 col2\" >21.9</td>\n",
       "                        <td id=\"T_12b91026_0054_11ea_9996_8c1abfa5692brow1_col3\" class=\"data row1 col3\" >22.1</td>\n",
       "                        <td id=\"T_12b91026_0054_11ea_9996_8c1abfa5692brow1_col4\" class=\"data row1 col4\" >22</td>\n",
       "                        <td id=\"T_12b91026_0054_11ea_9996_8c1abfa5692brow1_col5\" class=\"data row1 col5\" >21.9</td>\n",
       "                        <td id=\"T_12b91026_0054_11ea_9996_8c1abfa5692brow1_col6\" class=\"data row1 col6\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_12b91026_0054_11ea_9996_8c1abfa5692blevel0_row2\" class=\"row_heading level0 row2\" >West Virginia</th>\n",
       "                        <td id=\"T_12b91026_0054_11ea_9996_8c1abfa5692brow2_col0\" class=\"data row2 col0\" >69%</td>\n",
       "                        <td id=\"T_12b91026_0054_11ea_9996_8c1abfa5692brow2_col1\" class=\"data row2 col1\" >20</td>\n",
       "                        <td id=\"T_12b91026_0054_11ea_9996_8c1abfa5692brow2_col2\" class=\"data row2 col2\" >19.4</td>\n",
       "                        <td id=\"T_12b91026_0054_11ea_9996_8c1abfa5692brow2_col3\" class=\"data row2 col3\" >21.2</td>\n",
       "                        <td id=\"T_12b91026_0054_11ea_9996_8c1abfa5692brow2_col4\" class=\"data row2 col4\" >20.5</td>\n",
       "                        <td id=\"T_12b91026_0054_11ea_9996_8c1abfa5692brow2_col5\" class=\"data row2 col5\" >20.4</td>\n",
       "                        <td id=\"T_12b91026_0054_11ea_9996_8c1abfa5692brow2_col6\" class=\"data row2 col6\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_12b91026_0054_11ea_9996_8c1abfa5692blevel0_row3\" class=\"row_heading level0 row3\" >Wisconsin</th>\n",
       "                        <td id=\"T_12b91026_0054_11ea_9996_8c1abfa5692brow3_col0\" class=\"data row3 col0\" >100%</td>\n",
       "                        <td id=\"T_12b91026_0054_11ea_9996_8c1abfa5692brow3_col1\" class=\"data row3 col1\" >19.7</td>\n",
       "                        <td id=\"T_12b91026_0054_11ea_9996_8c1abfa5692brow3_col2\" class=\"data row3 col2\" >20.4</td>\n",
       "                        <td id=\"T_12b91026_0054_11ea_9996_8c1abfa5692brow3_col3\" class=\"data row3 col3\" >20.6</td>\n",
       "                        <td id=\"T_12b91026_0054_11ea_9996_8c1abfa5692brow3_col4\" class=\"data row3 col4\" >20.9</td>\n",
       "                        <td id=\"T_12b91026_0054_11ea_9996_8c1abfa5692brow3_col5\" class=\"data row3 col5\" >20.5</td>\n",
       "                        <td id=\"T_12b91026_0054_11ea_9996_8c1abfa5692brow3_col6\" class=\"data row3 col6\" >True</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_12b91026_0054_11ea_9996_8c1abfa5692blevel0_row4\" class=\"row_heading level0 row4\" >Wyoming</th>\n",
       "                        <td id=\"T_12b91026_0054_11ea_9996_8c1abfa5692brow4_col0\" class=\"data row4 col0\" >100%</td>\n",
       "                        <td id=\"T_12b91026_0054_11ea_9996_8c1abfa5692brow4_col1\" class=\"data row4 col1\" >19.4</td>\n",
       "                        <td id=\"T_12b91026_0054_11ea_9996_8c1abfa5692brow4_col2\" class=\"data row4 col2\" >19.8</td>\n",
       "                        <td id=\"T_12b91026_0054_11ea_9996_8c1abfa5692brow4_col3\" class=\"data row4 col3\" >20.8</td>\n",
       "                        <td id=\"T_12b91026_0054_11ea_9996_8c1abfa5692brow4_col4\" class=\"data row4 col4\" >20.6</td>\n",
       "                        <td id=\"T_12b91026_0054_11ea_9996_8c1abfa5692brow4_col5\" class=\"data row4 col5\" >20.2x</td>\n",
       "                        <td id=\"T_12b91026_0054_11ea_9996_8c1abfa5692brow4_col6\" class=\"data row4 col6\" >False</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0xd07cc30>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validate ACT CSV data with data from source @ https://blog.prepscholar.com/act-scores-by-state-averages-highs-and-lows\n",
    "\n",
    "# Set index (State) and rename columns of ACT CSV and source dataframes to facilitate validation later.\n",
    "\n",
    "act_2017_columns = ['Participation', 'English', 'Math', 'Reading', 'Science', 'Composite']\n",
    "\n",
    "df_act_2017.set_index('State', inplace=True)\n",
    "df_act_2017.columns = act_2017_columns\n",
    "\n",
    "\n",
    "def is_float(value):\n",
    "    try:\n",
    "        float(value)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def highlight_NaN_value(column):\n",
    "    \n",
    "    formats = ['' for i in range(column.size)]\n",
    "    \n",
    "    if column.name == 'Composite':\n",
    "        return ['background-color: yellow' if not is_float(value) else '' for value in column]\n",
    "    \n",
    "    return formats\n",
    "\n",
    "df_act_2017['is_composite_float'] = df_act_2017.apply(lambda row: is_float(row['Composite']), axis=1)\n",
    "df_act_2017.tail().style.apply(highlight_NaN_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fix this error, we change the Composite score of Wyoming to a numeric string (20.2) and convert the entire Composite score columnn to float values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 52 entries, National to Wyoming\n",
      "Data columns (total 6 columns):\n",
      "Participation    52 non-null object\n",
      "English          52 non-null float64\n",
      "Math             52 non-null float64\n",
      "Reading          52 non-null float64\n",
      "Science          52 non-null float64\n",
      "Composite        52 non-null float64\n",
      "dtypes: float64(5), object(1)\n",
      "memory usage: 3.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_act_2017.loc['Wyoming','Composite'] = 20.2\n",
    "\n",
    "df_act_2017['Composite'] = df_act_2017.apply(lambda row: float(row['Composite']), axis=1)\n",
    "\n",
    "df_act_2017.drop('is_composite_float', axis=1, inplace=True)\n",
    "\n",
    "df_act_2017.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can validate the ACT CSV dataset against its source, and address any errors found.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_2091eb7a_0054_11ea_8a48_8c1abfa5692brow0_col4 {\n",
       "            background-color:  yellow;\n",
       "        }    #T_2091eb7a_0054_11ea_8a48_8c1abfa5692brow1_col0 {\n",
       "            background-color:  yellow;\n",
       "        }</style><table id=\"T_2091eb7a_0054_11ea_8a48_8c1abfa5692b\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Participation</th>        <th class=\"col_heading level0 col1\" >English</th>        <th class=\"col_heading level0 col2\" >Math</th>        <th class=\"col_heading level0 col3\" >Reading</th>        <th class=\"col_heading level0 col4\" >Science</th>        <th class=\"col_heading level0 col5\" >Composite</th>        <th class=\"col_heading level0 col6\" >Participation_src</th>        <th class=\"col_heading level0 col7\" >English_src</th>        <th class=\"col_heading level0 col8\" >Math_src</th>        <th class=\"col_heading level0 col9\" >Reading_src</th>        <th class=\"col_heading level0 col10\" >Science_src</th>        <th class=\"col_heading level0 col11\" >Composite_src</th>    </tr>    <tr>        <th class=\"index_name level0\" >State</th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_2091eb7a_0054_11ea_8a48_8c1abfa5692blevel0_row0\" class=\"row_heading level0 row0\" >Maryland</th>\n",
       "                        <td id=\"T_2091eb7a_0054_11ea_8a48_8c1abfa5692brow0_col0\" class=\"data row0 col0\" >28%</td>\n",
       "                        <td id=\"T_2091eb7a_0054_11ea_8a48_8c1abfa5692brow0_col1\" class=\"data row0 col1\" >23.3</td>\n",
       "                        <td id=\"T_2091eb7a_0054_11ea_8a48_8c1abfa5692brow0_col2\" class=\"data row0 col2\" >23.1</td>\n",
       "                        <td id=\"T_2091eb7a_0054_11ea_8a48_8c1abfa5692brow0_col3\" class=\"data row0 col3\" >24.2</td>\n",
       "                        <td id=\"T_2091eb7a_0054_11ea_8a48_8c1abfa5692brow0_col4\" class=\"data row0 col4\" >2.3</td>\n",
       "                        <td id=\"T_2091eb7a_0054_11ea_8a48_8c1abfa5692brow0_col5\" class=\"data row0 col5\" >23.6</td>\n",
       "                        <td id=\"T_2091eb7a_0054_11ea_8a48_8c1abfa5692brow0_col6\" class=\"data row0 col6\" >28%</td>\n",
       "                        <td id=\"T_2091eb7a_0054_11ea_8a48_8c1abfa5692brow0_col7\" class=\"data row0 col7\" >23.3</td>\n",
       "                        <td id=\"T_2091eb7a_0054_11ea_8a48_8c1abfa5692brow0_col8\" class=\"data row0 col8\" >23.1</td>\n",
       "                        <td id=\"T_2091eb7a_0054_11ea_8a48_8c1abfa5692brow0_col9\" class=\"data row0 col9\" >24.2</td>\n",
       "                        <td id=\"T_2091eb7a_0054_11ea_8a48_8c1abfa5692brow0_col10\" class=\"data row0 col10\" >23.2</td>\n",
       "                        <td id=\"T_2091eb7a_0054_11ea_8a48_8c1abfa5692brow0_col11\" class=\"data row0 col11\" >23.6</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_2091eb7a_0054_11ea_8a48_8c1abfa5692blevel0_row1\" class=\"row_heading level0 row1\" >National</th>\n",
       "                        <td id=\"T_2091eb7a_0054_11ea_8a48_8c1abfa5692brow1_col0\" class=\"data row1 col0\" > 60%</td>\n",
       "                        <td id=\"T_2091eb7a_0054_11ea_8a48_8c1abfa5692brow1_col1\" class=\"data row1 col1\" >20.3</td>\n",
       "                        <td id=\"T_2091eb7a_0054_11ea_8a48_8c1abfa5692brow1_col2\" class=\"data row1 col2\" >20.7</td>\n",
       "                        <td id=\"T_2091eb7a_0054_11ea_8a48_8c1abfa5692brow1_col3\" class=\"data row1 col3\" >21.4</td>\n",
       "                        <td id=\"T_2091eb7a_0054_11ea_8a48_8c1abfa5692brow1_col4\" class=\"data row1 col4\" >21</td>\n",
       "                        <td id=\"T_2091eb7a_0054_11ea_8a48_8c1abfa5692brow1_col5\" class=\"data row1 col5\" >21</td>\n",
       "                        <td id=\"T_2091eb7a_0054_11ea_8a48_8c1abfa5692brow1_col6\" class=\"data row1 col6\" >60%</td>\n",
       "                        <td id=\"T_2091eb7a_0054_11ea_8a48_8c1abfa5692brow1_col7\" class=\"data row1 col7\" >20.3</td>\n",
       "                        <td id=\"T_2091eb7a_0054_11ea_8a48_8c1abfa5692brow1_col8\" class=\"data row1 col8\" >20.7</td>\n",
       "                        <td id=\"T_2091eb7a_0054_11ea_8a48_8c1abfa5692brow1_col9\" class=\"data row1 col9\" >21.4</td>\n",
       "                        <td id=\"T_2091eb7a_0054_11ea_8a48_8c1abfa5692brow1_col10\" class=\"data row1 col10\" >21</td>\n",
       "                        <td id=\"T_2091eb7a_0054_11ea_8a48_8c1abfa5692brow1_col11\" class=\"data row1 col11\" >21</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0xd073270>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load source SAT data from tab delimited file into dataframe.\n",
    "df_act_2017_source = pd.read_csv('../data/act_2017_source.txt', sep='\\t')\n",
    "df_act_2017_source.set_index('State', inplace=True)\n",
    "df_act_2017_source.columns = act_2017_columns\n",
    "df_act_2017_source.rename(columns=lambda col_name: col_name + '_src', inplace=True) \n",
    "\n",
    "# Join ACT CSV and source dataframes on row index 'State' \n",
    "df_act_2017_combined = df_act_2017.join(df_act_2017_source, 'State')\n",
    "\n",
    "df_act_2017_mismatched = df_act_2017_combined.loc[get_mismatched_indexes(df_act_2017_combined, act_2017_columns)]\n",
    "\n",
    "def highlight_act_mismatched(column):\n",
    "    \n",
    "    formats = ['' for i in range(column.size)]\n",
    "    \n",
    "    if column.name in act_2017_columns:\n",
    "        \n",
    "        is_mismatched = column != df_act_2017_mismatched[column.name + '_src']\n",
    "\n",
    "        return ['background-color: yellow' if mismatched else '' for mismatched in is_mismatched]\n",
    "    \n",
    "    return formats\n",
    "\n",
    "df_act_2017_mismatched.style.apply(highlight_act_mismatched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-referencing the ACT source, we found 2 errors:\n",
    "1. The Science score of Maryland should have been 23.2\n",
    "2. The national Participation rate differs from the source due to a leading whitespace. This error will be resolved when converting the Participation column from string to int values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4c. Fix any errors you identified\n",
    "\n",
    "**The data is available** so there's no need to guess or calculate anything. If you didn't find any errors, continue to the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the SAT dataset, we need to correct the Math score of Maryland to 524.\n",
    "For the ACT dataset, we need to correct the Science score of Maryland to 23.2.\n",
    "For both datasets, we need to convert Particatpation columns from string to float values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_23c34ce2_0054_11ea_957c_8c1abfa5692brow0_col2 {\n",
       "            background-color:  yellow;\n",
       "        }</style><table id=\"T_23c34ce2_0054_11ea_957c_8c1abfa5692b\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Participation</th>        <th class=\"col_heading level0 col1\" >EBRW</th>        <th class=\"col_heading level0 col2\" >Math</th>        <th class=\"col_heading level0 col3\" >Total</th>    </tr>    <tr>        <th class=\"index_name level0\" >State</th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_23c34ce2_0054_11ea_957c_8c1abfa5692blevel0_row0\" class=\"row_heading level0 row0\" >Maryland</th>\n",
       "                        <td id=\"T_23c34ce2_0054_11ea_957c_8c1abfa5692brow0_col0\" class=\"data row0 col0\" >69%</td>\n",
       "                        <td id=\"T_23c34ce2_0054_11ea_957c_8c1abfa5692brow0_col1\" class=\"data row0 col1\" >536</td>\n",
       "                        <td id=\"T_23c34ce2_0054_11ea_957c_8c1abfa5692brow0_col2\" class=\"data row0 col2\" >524</td>\n",
       "                        <td id=\"T_23c34ce2_0054_11ea_957c_8c1abfa5692brow0_col3\" class=\"data row0 col3\" >1060</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0xd8cae30>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def highlight_math_column(column):\n",
    "    \n",
    "    if column.name == 'Math':\n",
    "        return ['background-color: yellow']\n",
    "    else:\n",
    "        return ['']\n",
    "\n",
    "df_sat_2017.loc['Maryland','Math'] = 524\n",
    "df_sat_2017.loc[['Maryland']].style.apply(highlight_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_24eda71e_0054_11ea_b52e_8c1abfa5692brow0_col2 {\n",
       "            background-color:  yellow;\n",
       "        }</style><table id=\"T_24eda71e_0054_11ea_b52e_8c1abfa5692b\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Participation</th>        <th class=\"col_heading level0 col1\" >English</th>        <th class=\"col_heading level0 col2\" >Math</th>        <th class=\"col_heading level0 col3\" >Reading</th>        <th class=\"col_heading level0 col4\" >Science</th>        <th class=\"col_heading level0 col5\" >Composite</th>    </tr>    <tr>        <th class=\"index_name level0\" >State</th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_24eda71e_0054_11ea_b52e_8c1abfa5692blevel0_row0\" class=\"row_heading level0 row0\" >Maryland</th>\n",
       "                        <td id=\"T_24eda71e_0054_11ea_b52e_8c1abfa5692brow0_col0\" class=\"data row0 col0\" >28%</td>\n",
       "                        <td id=\"T_24eda71e_0054_11ea_b52e_8c1abfa5692brow0_col1\" class=\"data row0 col1\" >23.3</td>\n",
       "                        <td id=\"T_24eda71e_0054_11ea_b52e_8c1abfa5692brow0_col2\" class=\"data row0 col2\" >23.1</td>\n",
       "                        <td id=\"T_24eda71e_0054_11ea_b52e_8c1abfa5692brow0_col3\" class=\"data row0 col3\" >24.2</td>\n",
       "                        <td id=\"T_24eda71e_0054_11ea_b52e_8c1abfa5692brow0_col4\" class=\"data row0 col4\" >23.2</td>\n",
       "                        <td id=\"T_24eda71e_0054_11ea_b52e_8c1abfa5692brow0_col5\" class=\"data row0 col5\" >23.6</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0xd8cac30>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def highlight_science_column(column):\n",
    "    \n",
    "    if column.name == 'Science':\n",
    "        return ['background-color: yellow']\n",
    "    else:\n",
    "        return ['']\n",
    "\n",
    "df_act_2017.loc['Maryland','Science'] = 23.2\n",
    "df_act_2017.loc[['Maryland']].style.apply(highlight_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. What are your data types? \n",
    "Display the data types of each feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 51 entries, Alabama to Wyoming\n",
      "Data columns (total 4 columns):\n",
      "Participation    51 non-null object\n",
      "EBRW             51 non-null int64\n",
      "Math             51 non-null int64\n",
      "Total            51 non-null int64\n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 3.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_sat_2017.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 52 entries, National to Wyoming\n",
      "Data columns (total 6 columns):\n",
      "Participation    52 non-null object\n",
      "English          52 non-null float64\n",
      "Math             52 non-null float64\n",
      "Reading          52 non-null float64\n",
      "Science          52 non-null float64\n",
      "Composite        52 non-null float64\n",
      "dtypes: float64(5), object(1)\n",
      "memory usage: 3.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_act_2017.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did you learn?\n",
    "- Do any of them seem odd?  \n",
    "- Which ones are not as they should be?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Participation column (from both datasets) should be of integer data type to reflect percentages of state participation rates.\n",
    "\n",
    "Note: The Composite score column from the ACT dataset was converted from string to float data type earlier to facilitate validation against its source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Fix Incorrect Data Types\n",
    "Based on what you discovered above, use appropriate methods to re-type incorrectly typed data.\n",
    "- Define a function that will allow you to convert participation rates to an appropriate numeric type. Use `map` or `apply` to change these columns in each dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove \n",
    "\n",
    "def to_int_column(df, col_name):\n",
    "    df[col_name] = df.apply(lambda row: int(row[col_name].strip()[:-1]), axis=1)\n",
    "\n",
    "to_int_column(df_sat_2017, 'Participation')\n",
    "to_int_column(df_act_2017, 'Participation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fix any individual values preventing other columns from being the appropriate type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Finish your data modifications by making sure the columns are now typed appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Display the data types again to confirm they are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 51 entries, Alabama to Wyoming\n",
      "Data columns (total 4 columns):\n",
      "Participation    51 non-null int64\n",
      "EBRW             51 non-null int64\n",
      "Math             51 non-null int64\n",
      "Total            51 non-null int64\n",
      "dtypes: int64(4)\n",
      "memory usage: 3.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_sat_2017.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 52 entries, National to Wyoming\n",
      "Data columns (total 6 columns):\n",
      "Participation    52 non-null int64\n",
      "English          52 non-null float64\n",
      "Math             52 non-null float64\n",
      "Reading          52 non-null float64\n",
      "Science          52 non-null float64\n",
      "Composite        52 non-null float64\n",
      "dtypes: float64(5), int64(1)\n",
      "memory usage: 4.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_act_2017.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Rename Columns\n",
    "Change the names of the columns to more expressive names so that you can tell the difference the SAT columns and the ACT columns. Your solution should map all column names being changed at once (no repeated singular name-changes). **We will be combining these data with some of the data from 2018, and so you should name columns in an appropriate way**.\n",
    "\n",
    "**Guidelines**:\n",
    "- Column names should be all lowercase (you will thank yourself when you start pushing data to SQL later in the course)\n",
    "- Column names should not contain spaces (underscores will suffice--this allows for using the `df.column_name` method to access columns in addition to `df['column_name']`.\n",
    "- Column names should be unique and informative (the only feature that we actually share between dataframes is the state)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename index and column names to lowercase. Append pfrefix 'sat_' or 'act_' to the respective datasets.  \n",
    "df_sat_2017.index.name = 'state'\n",
    "df_sat_2017.columns = ['sat_participation', 'sat_EBRW', 'sat_math', 'sat_total']\n",
    "\n",
    "df_act_2017.index.name = 'state'\n",
    "df_act_2017.columns = ['act_participation', 'act_english', 'act_math', 'act_reading', 'act_science', 'act_composite']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Create a data dictionary\n",
    "\n",
    "Now that we've fixed our data, and given it appropriate names, let's create a [data dictionary](http://library.ucmerced.edu/node/10249). \n",
    "\n",
    "A data dictionary provides a quick overview of features/variables/columns, alongside data types and descriptions. The more descriptive you can be, the more useful this document is.\n",
    "\n",
    "Example of a Fictional Data Dictionary Entry: \n",
    "\n",
    "|Feature|Type|Dataset|Description|\n",
    "|---|---|---|---|\n",
    "|**county_pop**|*integer*|2010 census|The population of the county (units in thousands, where 2.5 represents 2500 people).| \n",
    "|**per_poverty**|*float*|2010 census|The percent of the county over the age of 18 living below the 200% of official US poverty rate (units percent to two decimal places 98.10 means 98.1%)|\n",
    "\n",
    "[Here's a quick link to a short guide for formatting markdown in Jupyter notebooks](https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Working%20With%20Markdown%20Cells.html).\n",
    "\n",
    "Provided is the skeleton for formatting a markdown table, with columns headers that will help you create a data dictionary to quickly summarize your data, as well as some examples. **This would be a great thing to copy and paste into your custom README for this project.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Feature|Type|Dataset|Description|\n",
    "|---|---|---|---|\n",
    "|sat_participation|int|SAT|Percentage of students in the state taking the SAT college admissions test.| \n",
    "|sat_EBRW|int|SAT|Evidence-Based Reading Writing score of the SAT test.| \n",
    "|sat_math|int|SAT|Math score of the SAT test.| \n",
    "|sat_total|int|SAT|Total score of the SAT test (EBRW + Math score).| \n",
    "|act_participation|int|ACT|Percentage of students in the state taking the ACT college admissions test.| \n",
    "|act_english|float|ACT|English score of the ACT test.| \n",
    "|act_math|float|ACT|Math score of the ACT test.| \n",
    "|act_reading|float|ACT|Reading score of the ACT test.| \n",
    "|act_science|float|ACT|Science score of the ACT test.| \n",
    "|act_composite|float|ACT|Composite score of the ACT test (Average of English, Math, Reading and Science scores).| "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Drop unnecessary rows\n",
    "\n",
    "One of our dataframes contains an extra row. Identify and remove this from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act_participation</th>\n",
       "      <th>act_english</th>\n",
       "      <th>act_math</th>\n",
       "      <th>act_reading</th>\n",
       "      <th>act_science</th>\n",
       "      <th>act_composite</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>National</th>\n",
       "      <td>60</td>\n",
       "      <td>20.3</td>\n",
       "      <td>20.7</td>\n",
       "      <td>21.4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alabama</th>\n",
       "      <td>100</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.4</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alaska</th>\n",
       "      <td>65</td>\n",
       "      <td>18.7</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.4</td>\n",
       "      <td>19.9</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arizona</th>\n",
       "      <td>62</td>\n",
       "      <td>18.6</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.1</td>\n",
       "      <td>19.8</td>\n",
       "      <td>19.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arkansas</th>\n",
       "      <td>100</td>\n",
       "      <td>18.9</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <td>31</td>\n",
       "      <td>22.5</td>\n",
       "      <td>22.7</td>\n",
       "      <td>23.1</td>\n",
       "      <td>22.2</td>\n",
       "      <td>22.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Colorado</th>\n",
       "      <td>100</td>\n",
       "      <td>20.1</td>\n",
       "      <td>20.3</td>\n",
       "      <td>21.2</td>\n",
       "      <td>20.9</td>\n",
       "      <td>20.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Connecticut</th>\n",
       "      <td>31</td>\n",
       "      <td>25.5</td>\n",
       "      <td>24.6</td>\n",
       "      <td>25.6</td>\n",
       "      <td>24.6</td>\n",
       "      <td>25.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Delaware</th>\n",
       "      <td>18</td>\n",
       "      <td>24.1</td>\n",
       "      <td>23.4</td>\n",
       "      <td>24.8</td>\n",
       "      <td>23.6</td>\n",
       "      <td>24.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>District of Columbia</th>\n",
       "      <td>32</td>\n",
       "      <td>24.4</td>\n",
       "      <td>23.5</td>\n",
       "      <td>24.9</td>\n",
       "      <td>23.5</td>\n",
       "      <td>24.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Florida</th>\n",
       "      <td>73</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Georgia</th>\n",
       "      <td>55</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20.9</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.3</td>\n",
       "      <td>21.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hawaii</th>\n",
       "      <td>90</td>\n",
       "      <td>17.8</td>\n",
       "      <td>19.2</td>\n",
       "      <td>19.2</td>\n",
       "      <td>19.3</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Idaho</th>\n",
       "      <td>38</td>\n",
       "      <td>21.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>23.0</td>\n",
       "      <td>22.1</td>\n",
       "      <td>22.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Illinois</th>\n",
       "      <td>93</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.2</td>\n",
       "      <td>21.6</td>\n",
       "      <td>21.3</td>\n",
       "      <td>21.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indiana</th>\n",
       "      <td>35</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.4</td>\n",
       "      <td>23.2</td>\n",
       "      <td>22.3</td>\n",
       "      <td>22.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iowa</th>\n",
       "      <td>67</td>\n",
       "      <td>21.2</td>\n",
       "      <td>21.3</td>\n",
       "      <td>22.6</td>\n",
       "      <td>22.1</td>\n",
       "      <td>21.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kansas</th>\n",
       "      <td>73</td>\n",
       "      <td>21.1</td>\n",
       "      <td>21.3</td>\n",
       "      <td>22.3</td>\n",
       "      <td>21.7</td>\n",
       "      <td>21.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kentucky</th>\n",
       "      <td>100</td>\n",
       "      <td>19.6</td>\n",
       "      <td>19.4</td>\n",
       "      <td>20.5</td>\n",
       "      <td>20.1</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Louisiana</th>\n",
       "      <td>100</td>\n",
       "      <td>19.4</td>\n",
       "      <td>18.8</td>\n",
       "      <td>19.8</td>\n",
       "      <td>19.6</td>\n",
       "      <td>19.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maine</th>\n",
       "      <td>8</td>\n",
       "      <td>24.2</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.8</td>\n",
       "      <td>23.7</td>\n",
       "      <td>24.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Maryland</th>\n",
       "      <td>28</td>\n",
       "      <td>23.3</td>\n",
       "      <td>23.1</td>\n",
       "      <td>24.2</td>\n",
       "      <td>23.2</td>\n",
       "      <td>23.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Massachusetts</th>\n",
       "      <td>29</td>\n",
       "      <td>25.4</td>\n",
       "      <td>25.3</td>\n",
       "      <td>25.9</td>\n",
       "      <td>24.7</td>\n",
       "      <td>25.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Michigan</th>\n",
       "      <td>29</td>\n",
       "      <td>24.1</td>\n",
       "      <td>23.7</td>\n",
       "      <td>24.5</td>\n",
       "      <td>23.8</td>\n",
       "      <td>24.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Minnesota</th>\n",
       "      <td>100</td>\n",
       "      <td>20.4</td>\n",
       "      <td>21.5</td>\n",
       "      <td>21.8</td>\n",
       "      <td>21.6</td>\n",
       "      <td>21.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mississippi</th>\n",
       "      <td>100</td>\n",
       "      <td>18.2</td>\n",
       "      <td>18.1</td>\n",
       "      <td>18.8</td>\n",
       "      <td>18.8</td>\n",
       "      <td>18.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Missouri</th>\n",
       "      <td>100</td>\n",
       "      <td>19.8</td>\n",
       "      <td>19.9</td>\n",
       "      <td>20.8</td>\n",
       "      <td>20.5</td>\n",
       "      <td>20.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Montana</th>\n",
       "      <td>100</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20.5</td>\n",
       "      <td>20.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nebraska</th>\n",
       "      <td>84</td>\n",
       "      <td>20.9</td>\n",
       "      <td>20.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>21.5</td>\n",
       "      <td>21.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nevada</th>\n",
       "      <td>100</td>\n",
       "      <td>16.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.1</td>\n",
       "      <td>18.2</td>\n",
       "      <td>17.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Hampshire</th>\n",
       "      <td>18</td>\n",
       "      <td>25.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>24.9</td>\n",
       "      <td>25.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Jersey</th>\n",
       "      <td>34</td>\n",
       "      <td>23.8</td>\n",
       "      <td>23.8</td>\n",
       "      <td>24.1</td>\n",
       "      <td>23.2</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Mexico</th>\n",
       "      <td>66</td>\n",
       "      <td>18.6</td>\n",
       "      <td>19.4</td>\n",
       "      <td>20.4</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York</th>\n",
       "      <td>31</td>\n",
       "      <td>23.8</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>23.9</td>\n",
       "      <td>24.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North Carolina</th>\n",
       "      <td>100</td>\n",
       "      <td>17.8</td>\n",
       "      <td>19.3</td>\n",
       "      <td>19.6</td>\n",
       "      <td>19.3</td>\n",
       "      <td>19.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North Dakota</th>\n",
       "      <td>98</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.4</td>\n",
       "      <td>20.5</td>\n",
       "      <td>20.6</td>\n",
       "      <td>20.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ohio</th>\n",
       "      <td>75</td>\n",
       "      <td>21.2</td>\n",
       "      <td>21.6</td>\n",
       "      <td>22.5</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oklahoma</th>\n",
       "      <td>100</td>\n",
       "      <td>18.5</td>\n",
       "      <td>18.8</td>\n",
       "      <td>20.1</td>\n",
       "      <td>19.6</td>\n",
       "      <td>19.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oregon</th>\n",
       "      <td>40</td>\n",
       "      <td>21.2</td>\n",
       "      <td>21.5</td>\n",
       "      <td>22.4</td>\n",
       "      <td>21.7</td>\n",
       "      <td>21.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pennsylvania</th>\n",
       "      <td>23</td>\n",
       "      <td>23.4</td>\n",
       "      <td>23.4</td>\n",
       "      <td>24.2</td>\n",
       "      <td>23.3</td>\n",
       "      <td>23.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rhode Island</th>\n",
       "      <td>21</td>\n",
       "      <td>24.0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>24.7</td>\n",
       "      <td>23.4</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Carolina</th>\n",
       "      <td>100</td>\n",
       "      <td>17.5</td>\n",
       "      <td>18.6</td>\n",
       "      <td>19.1</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Dakota</th>\n",
       "      <td>80</td>\n",
       "      <td>20.7</td>\n",
       "      <td>21.5</td>\n",
       "      <td>22.3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tennessee</th>\n",
       "      <td>100</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.2</td>\n",
       "      <td>20.1</td>\n",
       "      <td>19.9</td>\n",
       "      <td>19.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Texas</th>\n",
       "      <td>45</td>\n",
       "      <td>19.5</td>\n",
       "      <td>20.7</td>\n",
       "      <td>21.1</td>\n",
       "      <td>20.9</td>\n",
       "      <td>20.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Utah</th>\n",
       "      <td>100</td>\n",
       "      <td>19.5</td>\n",
       "      <td>19.9</td>\n",
       "      <td>20.8</td>\n",
       "      <td>20.6</td>\n",
       "      <td>20.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vermont</th>\n",
       "      <td>29</td>\n",
       "      <td>23.3</td>\n",
       "      <td>23.1</td>\n",
       "      <td>24.4</td>\n",
       "      <td>23.2</td>\n",
       "      <td>23.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Virginia</th>\n",
       "      <td>29</td>\n",
       "      <td>23.5</td>\n",
       "      <td>23.3</td>\n",
       "      <td>24.6</td>\n",
       "      <td>23.5</td>\n",
       "      <td>23.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Washington</th>\n",
       "      <td>29</td>\n",
       "      <td>20.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>22.1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>West Virginia</th>\n",
       "      <td>69</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>21.2</td>\n",
       "      <td>20.5</td>\n",
       "      <td>20.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wisconsin</th>\n",
       "      <td>100</td>\n",
       "      <td>19.7</td>\n",
       "      <td>20.4</td>\n",
       "      <td>20.6</td>\n",
       "      <td>20.9</td>\n",
       "      <td>20.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wyoming</th>\n",
       "      <td>100</td>\n",
       "      <td>19.4</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.8</td>\n",
       "      <td>20.6</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      act_participation  act_english  act_math  act_reading  \\\n",
       "state                                                                         \n",
       "National                             60         20.3      20.7         21.4   \n",
       "Alabama                             100         18.9      18.4         19.7   \n",
       "Alaska                               65         18.7      19.8         20.4   \n",
       "Arizona                              62         18.6      19.8         20.1   \n",
       "Arkansas                            100         18.9      19.0         19.7   \n",
       "California                           31         22.5      22.7         23.1   \n",
       "Colorado                            100         20.1      20.3         21.2   \n",
       "Connecticut                          31         25.5      24.6         25.6   \n",
       "Delaware                             18         24.1      23.4         24.8   \n",
       "District of Columbia                 32         24.4      23.5         24.9   \n",
       "Florida                              73         19.0      19.4         21.0   \n",
       "Georgia                              55         21.0      20.9         22.0   \n",
       "Hawaii                               90         17.8      19.2         19.2   \n",
       "Idaho                                38         21.9      21.8         23.0   \n",
       "Illinois                             93         21.0      21.2         21.6   \n",
       "Indiana                              35         22.0      22.4         23.2   \n",
       "Iowa                                 67         21.2      21.3         22.6   \n",
       "Kansas                               73         21.1      21.3         22.3   \n",
       "Kentucky                            100         19.6      19.4         20.5   \n",
       "Louisiana                           100         19.4      18.8         19.8   \n",
       "Maine                                 8         24.2      24.0         24.8   \n",
       "Maryland                             28         23.3      23.1         24.2   \n",
       "Massachusetts                        29         25.4      25.3         25.9   \n",
       "Michigan                             29         24.1      23.7         24.5   \n",
       "Minnesota                           100         20.4      21.5         21.8   \n",
       "Mississippi                         100         18.2      18.1         18.8   \n",
       "Missouri                            100         19.8      19.9         20.8   \n",
       "Montana                             100         19.0      20.2         21.0   \n",
       "Nebraska                             84         20.9      20.9         21.9   \n",
       "Nevada                              100         16.3      18.0         18.1   \n",
       "New Hampshire                        18         25.4      25.1         26.0   \n",
       "New Jersey                           34         23.8      23.8         24.1   \n",
       "New Mexico                           66         18.6      19.4         20.4   \n",
       "New York                             31         23.8      24.0         24.6   \n",
       "North Carolina                      100         17.8      19.3         19.6   \n",
       "North Dakota                         98         19.0      20.4         20.5   \n",
       "Ohio                                 75         21.2      21.6         22.5   \n",
       "Oklahoma                            100         18.5      18.8         20.1   \n",
       "Oregon                               40         21.2      21.5         22.4   \n",
       "Pennsylvania                         23         23.4      23.4         24.2   \n",
       "Rhode Island                         21         24.0      23.3         24.7   \n",
       "South Carolina                      100         17.5      18.6         19.1   \n",
       "South Dakota                         80         20.7      21.5         22.3   \n",
       "Tennessee                           100         19.5      19.2         20.1   \n",
       "Texas                                45         19.5      20.7         21.1   \n",
       "Utah                                100         19.5      19.9         20.8   \n",
       "Vermont                              29         23.3      23.1         24.4   \n",
       "Virginia                             29         23.5      23.3         24.6   \n",
       "Washington                           29         20.9      21.9         22.1   \n",
       "West Virginia                        69         20.0      19.4         21.2   \n",
       "Wisconsin                           100         19.7      20.4         20.6   \n",
       "Wyoming                             100         19.4      19.8         20.8   \n",
       "\n",
       "                      act_science  act_composite  \n",
       "state                                             \n",
       "National                     21.0           21.0  \n",
       "Alabama                      19.4           19.2  \n",
       "Alaska                       19.9           19.8  \n",
       "Arizona                      19.8           19.7  \n",
       "Arkansas                     19.5           19.4  \n",
       "California                   22.2           22.8  \n",
       "Colorado                     20.9           20.8  \n",
       "Connecticut                  24.6           25.2  \n",
       "Delaware                     23.6           24.1  \n",
       "District of Columbia         23.5           24.2  \n",
       "Florida                      19.4           19.8  \n",
       "Georgia                      21.3           21.4  \n",
       "Hawaii                       19.3           19.0  \n",
       "Idaho                        22.1           22.3  \n",
       "Illinois                     21.3           21.4  \n",
       "Indiana                      22.3           22.6  \n",
       "Iowa                         22.1           21.9  \n",
       "Kansas                       21.7           21.7  \n",
       "Kentucky                     20.1           20.0  \n",
       "Louisiana                    19.6           19.5  \n",
       "Maine                        23.7           24.3  \n",
       "Maryland                     23.2           23.6  \n",
       "Massachusetts                24.7           25.4  \n",
       "Michigan                     23.8           24.1  \n",
       "Minnesota                    21.6           21.5  \n",
       "Mississippi                  18.8           18.6  \n",
       "Missouri                     20.5           20.4  \n",
       "Montana                      20.5           20.3  \n",
       "Nebraska                     21.5           21.4  \n",
       "Nevada                       18.2           17.8  \n",
       "New Hampshire                24.9           25.5  \n",
       "New Jersey                   23.2           23.9  \n",
       "New Mexico                   20.0           19.7  \n",
       "New York                     23.9           24.2  \n",
       "North Carolina               19.3           19.1  \n",
       "North Dakota                 20.6           20.3  \n",
       "Ohio                         22.0           22.0  \n",
       "Oklahoma                     19.6           19.4  \n",
       "Oregon                       21.7           21.8  \n",
       "Pennsylvania                 23.3           23.7  \n",
       "Rhode Island                 23.4           24.0  \n",
       "South Carolina               18.9           18.7  \n",
       "South Dakota                 22.0           21.8  \n",
       "Tennessee                    19.9           19.8  \n",
       "Texas                        20.9           20.7  \n",
       "Utah                         20.6           20.3  \n",
       "Vermont                      23.2           23.6  \n",
       "Virginia                     23.5           23.8  \n",
       "Washington                   22.0           21.9  \n",
       "West Virginia                20.5           20.4  \n",
       "Wisconsin                    20.9           20.5  \n",
       "Wyoming                      20.6           20.2  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_act_2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Merge Dataframes\n",
    "\n",
    "Join the 2017 ACT and SAT dataframes using the state in each dataframe as the key. Assign this to a new variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Save your cleaned, merged dataframe\n",
    "\n",
    "Use a relative path to save out your data as `combined_2017.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2018 Data Import and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Links to the 2018 ACT and SAT data are provided in the README. These data live in PDFs, and so you'll get to enjoy practicing some *manual* data collection. Save these data as a CSV in your `data` directory, and import, explore, and clean these data in the same way you did above. **Make sure you comment on your steps so it is clear *why* you are doing each process**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine your 2017 and 2018 data into a single dataframe\n",
    "Joining on state names should work, assuming you formatted all your state names identically. Make sure none of your columns (other than state) have identical names. Do yourself a favor and decide if you're encoding participation rates as floats or integers and standardize this across your datasets.\n",
    "\n",
    "Save the contents of this merged dataframe as `final.csv`.\n",
    "\n",
    "**Use this combined dataframe for the remainder of the project**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "\n",
    "### Summary Statistics\n",
    "Transpose the output of pandas `describe` method to create a quick overview of each numeric feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manually calculate standard deviation\n",
    "\n",
    "$$\\sigma = \\sqrt{\\frac{1}{n}\\sum_{i=1}^n(x_i - \\mu)^2}$$\n",
    "\n",
    "- Write a function to calculate standard deviation using the formula above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use a **dictionary comprehension** to apply your standard deviation function to each numeric column in the dataframe.  **No loops**  \n",
    "- Assign the output to variable `sd` as a dictionary where: \n",
    "    - Each column name is now a key \n",
    "    - That standard deviation of the column is the value \n",
    "     \n",
    "*Example Output :* `{'ACT_Math': 120, 'ACT_Reading': 120, ...}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do your manually calculated standard deviations match up with the output from pandas `describe`? What about numpy's `std` method?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigate trends in the data\n",
    "Using sorting and/or masking (along with the `.head` method to not print our entire dataframe), consider the following questions:\n",
    "\n",
    "- Which states have the highest and lowest participation rates for the:\n",
    "    - 2017 SAT?\n",
    "    - 2018 SAT?\n",
    "    - 2017 ACT?\n",
    "    - 2018 ACT?\n",
    "- Which states have the highest and lowest mean total/composite scores for the:\n",
    "    - 2017 SAT?\n",
    "    - 2018 SAT?\n",
    "    - 2017 ACT?\n",
    "    - 2018 ACT?\n",
    "- Do any states with 100% participation on a given test have a rate change year-to-year?\n",
    "- Do any states show have >50% participation on *both* tests either year?\n",
    "\n",
    "Based on what you've just observed, have you identified any states that you're especially interested in? **Make a note of these and state *why* you think they're interesting**.\n",
    "\n",
    "**You should comment on your findings at each step in a markdown cell below your code block**. Make sure you include at least one example of sorting your dataframe by a column, and one example of using boolean filtering (i.e., masking) to select a subset of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the data\n",
    "\n",
    "There's not a magic bullet recommendation for the right number of plots to understand a given dataset, but visualizing your data is *always* a good idea. Not only does it allow you to quickly convey your findings (even if you have a non-technical audience), it will often reveal trends in your data that escaped you when you were looking only at numbers.\n",
    "\n",
    "Some recommendations on plotting:\n",
    "- Plots have titles\n",
    "- Plots have axis labels\n",
    "- Plots have appropriate tick labels\n",
    "- All text is legible in a plot\n",
    "- Plots demonstrate meaningful and valid relationships\n",
    "- Plots are interpreted to aid understanding\n",
    "\n",
    "There is such a thing as too many plots, and there are a *lot* of bad plots. You might make some! (But hopefully not with the guided prompts below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Seaborn's heatmap with pandas `.corr()` to visualize correlations between all numeric features\n",
    "\n",
    "Heatmaps are generally not appropriate for presentations, and should often be excluded from reports as they can be visually overwhelming. **However**, they can be extremely useful in identify relationships of potential interest (as well as identifying potential collinearity before modeling).\n",
    "\n",
    "*example*:\n",
    "```python\n",
    "sns.heatmap(df.corr())\n",
    "```\n",
    "\n",
    "Please take time to format your output, adding a title. Look through some of the additional arguments and options. (Axis labels aren't really necessary, as long as the title is informative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a custom function to subplot histograms\n",
    "\n",
    "We have data for two tests for two years. We only have composite (and not subtest scores) for the 2018 ACT. We should write a function that will take the names of 2+ columns and subplot histograms. While you can use pandas plotting or Seaborn here, matplotlib gives you greater control over all aspects of your plots.\n",
    "\n",
    "[Helpful Link for Plotting Multiple Figures](https://matplotlib.org/users/pyplot_tutorial.html#working-with-multiple-figures-and-axes)\n",
    "\n",
    "Here's some starter code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subplot_histograms(dataframe, list_of_columns, list_of_titles, list_of_xlabels):\n",
    "    nrows = int(np.ceil(len(list_of_columns)/2)) # Makes sure you have enough rows\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=2) # You'll want to specify your figsize\n",
    "    ax = ax.ravel() # Ravel turns a matrix into a vector, which is easier to iterate\n",
    "    for i, column in enumerate(list_of_columns): # Gives us an index value to get into all our lists\n",
    "        ax[i].hist(dataframe[column]) # feel free to add more settings\n",
    "        # Set titles, labels, etc here for each subplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot and interpret histograms \n",
    "For each of the following:\n",
    "- Participation rates for SAT & ACT\n",
    "- Math scores for SAT & ACT\n",
    "- Reading/verbal scores for SAT & ACT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot and interpret scatter plots\n",
    "\n",
    "For each of the following:\n",
    "- SAT vs. ACT math scores for 2017\n",
    "- SAT vs. ACT verbal/reading scores for 2017\n",
    "- SAT vs. ACT total/composite scores for 2017\n",
    "- Total scores for SAT 2017 vs. 2018\n",
    "- Composite scores for ACT 2017 vs. 2018\n",
    "\n",
    "Plot the two variables against each other using matplotlib or Seaborn\n",
    "\n",
    "Your plots should show:\n",
    "- Two clearly labeled axes\n",
    "- A proper title\n",
    "- Using colors and symbols that are clear and unmistakable\n",
    "\n",
    "**Feel free to write a custom function, and subplot if you'd like.** Functions save both time and space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot and interpret boxplots\n",
    "\n",
    "For each numeric variable in the dataframe create a boxplot using Seaborn. Boxplots demonstrate central tendency and spread in variables. In a certain sense, these are somewhat redundant with histograms, but you may be better able to identify clear outliers or differences in IQR, etc.\n",
    "\n",
    "Multiple values can be plotted to a single boxplot as long as they are of the same relative scale (meaning they have similar min/max values).\n",
    "\n",
    "Each boxplot should:\n",
    "- Only include variables of a similar scale\n",
    "- Have clear labels for each variable\n",
    "- Have appropriate titles and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feel free to do additional plots below\n",
    "*(do research and choose your own chart types & variables)*\n",
    "\n",
    "Are there any additional trends or relationships you haven't explored? Was there something interesting you saw that you'd like to dive further into? It's likely that there are a few more plots you might want to generate to support your narrative and recommendations that you are building toward. **As always, make sure you're interpreting your plots as you go**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Optional): Using Tableau, create a choropleth map for each variable using a map of the US. \n",
    "\n",
    "Save this plot as an image file in an images directory, provide a relative path, and insert the image into notebook in markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive and Inferential Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarizing Distributions\n",
    "\n",
    "Above, we used pandas `describe` to provide quick summary statistics of our numeric columns. We also demonstrated many visual relationships.\n",
    "\n",
    "As data scientists, having a complete understanding of data is imperative prior to modeling.\n",
    "\n",
    "While we will continue to build our analytic tools, we know that measures of *central tendency*, *spread*, and *shape/skewness* provide a quick summary of distributions.\n",
    "\n",
    "For each variable in your data, summarize the underlying distributions (in words & statistics)\n",
    " - Be thorough in your verbal description of these distributions.\n",
    " - Be sure to back up these summaries with statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answers:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We generally assuming that data we sample from a population will be normally distributed. Do we observe this trend?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does This Assumption Hold for:\n",
    "    - Math\n",
    "    - Reading\n",
    "    - Rates\n",
    "Explain your answers for each distribution and how you think this will affect estimates made from these data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimate Limits of Data\n",
    "\n",
    "Suppose we only seek to understand the relationship between SAT and ACT participation rates in 2017. \n",
    "\n",
    "##### Does it make sense to conduct statistical inference given these data specifically? \n",
    "\n",
    "Why or why not?\n",
    "\n",
    "*(think about granularity, aggregation, the relationships between populations size & rates...consider the actually populations these data describe in answering this question)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Is it appropriate to compare *these* specific SAT and ACT math scores? \n",
    "\n",
    "Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistical Evaluation of Distributions \n",
    "\n",
    "**If you feel it's appropriate**, using methods we discussed in class, run hypothesis tests to compare variables of interest in our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outside Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based upon your observations, choose **three** states that demonstrate interesting trends in their SAT and/or ACT participation rates. Spend some time doing outside research on state policies that might influence these rates, and summarize your findings below. **Feel free to go back and create new plots that highlight these states of interest**. If you bring in any outside tables or charts, make sure you are explicit about having borrowed them. If you quote any text, make sure that it renders as being quoted. (Make sure that you cite your sources -- check with you local instructor for citation preferences)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on your exploration of the data, what are you key takeaways and recommendations? Choose one state with a lower participation rate and provide a suggestion for how the College Board might increase participation amongst graduating seniors in this state. Are there additional data you desire that would better inform your investigations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
